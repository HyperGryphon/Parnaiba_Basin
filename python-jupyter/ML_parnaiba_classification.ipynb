{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUlllNKMcZpQ",
    "outputId": "71abcba5-1cfd-4677-920f-919ee9f4883e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.mixture import GaussianMixture\n",
    "#import skbio.stats.composition as comp\n",
    "import plotly.express as px\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm # SVC para classificação (target discreto) e SVR para regressão (traget contínuo)\n",
    "from sklearn.ensemble import RandomForestClassifier #só classificação\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn import metrics\n",
    "import GeoSed_stat_funcs as gs\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "SYMWLhXyXTyK",
    "outputId": "be6e8849-0f30-4d53-a013-f85e3fd5eabc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Group</th>\n",
       "      <th>BOSL1s</th>\n",
       "      <th>BOSLF</th>\n",
       "      <th>BOSLM</th>\n",
       "      <th>BOSLS</th>\n",
       "      <th>IRSL1.2s/BOSL1s</th>\n",
       "      <th>TL110oC</th>\n",
       "      <th>TL110pos</th>\n",
       "      <th>TL325pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bp100</td>\n",
       "      <td>Serra Grande</td>\n",
       "      <td>Serra Grande</td>\n",
       "      <td>12.811713</td>\n",
       "      <td>38.068407</td>\n",
       "      <td>33.330574</td>\n",
       "      <td>28.601019</td>\n",
       "      <td>19.076664</td>\n",
       "      <td>76.183863</td>\n",
       "      <td>96.2</td>\n",
       "      <td>325.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bp100</td>\n",
       "      <td>Serra Grande</td>\n",
       "      <td>Serra Grande</td>\n",
       "      <td>12.221442</td>\n",
       "      <td>38.772984</td>\n",
       "      <td>31.830463</td>\n",
       "      <td>29.396553</td>\n",
       "      <td>29.591771</td>\n",
       "      <td>75.658334</td>\n",
       "      <td>96.2</td>\n",
       "      <td>325.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bp100</td>\n",
       "      <td>Serra Grande</td>\n",
       "      <td>Serra Grande</td>\n",
       "      <td>13.004011</td>\n",
       "      <td>40.739419</td>\n",
       "      <td>32.236592</td>\n",
       "      <td>27.023990</td>\n",
       "      <td>17.354350</td>\n",
       "      <td>77.313586</td>\n",
       "      <td>96.2</td>\n",
       "      <td>325.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bp100</td>\n",
       "      <td>Serra Grande</td>\n",
       "      <td>Serra Grande</td>\n",
       "      <td>11.314952</td>\n",
       "      <td>39.443369</td>\n",
       "      <td>31.129080</td>\n",
       "      <td>29.427551</td>\n",
       "      <td>27.822570</td>\n",
       "      <td>76.931064</td>\n",
       "      <td>96.2</td>\n",
       "      <td>324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bp102</td>\n",
       "      <td>Serra Grande</td>\n",
       "      <td>Serra Grande</td>\n",
       "      <td>3.490668</td>\n",
       "      <td>5.954731</td>\n",
       "      <td>19.595849</td>\n",
       "      <td>74.449419</td>\n",
       "      <td>121.146848</td>\n",
       "      <td>58.377886</td>\n",
       "      <td>98.0</td>\n",
       "      <td>334.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample          Unit         Group     BOSL1s      BOSLF      BOSLM  \\\n",
       "0  bp100  Serra Grande  Serra Grande  12.811713  38.068407  33.330574   \n",
       "1  bp100  Serra Grande  Serra Grande  12.221442  38.772984  31.830463   \n",
       "2  bp100  Serra Grande  Serra Grande  13.004011  40.739419  32.236592   \n",
       "3  bp100  Serra Grande  Serra Grande  11.314952  39.443369  31.129080   \n",
       "4  bp102  Serra Grande  Serra Grande   3.490668   5.954731  19.595849   \n",
       "\n",
       "       BOSLS  IRSL1.2s/BOSL1s    TL110oC  TL110pos  TL325pos  \n",
       "0  28.601019        19.076664  76.183863      96.2     325.8  \n",
       "1  29.396553        29.591771  75.658334      96.2     325.8  \n",
       "2  27.023990        17.354350  77.313586      96.2     325.8  \n",
       "3  29.427551        27.822570  76.931064      96.2     324.0  \n",
       "4  74.449419       121.146848  58.377886      98.0     334.8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cabecas' 'Longa' 'Motuca' 'Piaui' 'Pimenteiras' 'Poti' 'Sambaiba'\n",
      " 'Serra Grande']\n"
     ]
    }
   ],
   "source": [
    "df0=pd.read_excel('C:\\\\Users\\\\iande\\\\Documentos\\\\proyectos\\\\ML with lumi data\\\\osl_parnaiba_table.xlsx',sheet_name=\"by_aliquot\")\n",
    "df0 = df0.drop(columns=['Unnamed: 0'])\n",
    "df0 = df0.fillna(33.333)\n",
    "display(df0.head())\n",
    "print(np.unique(df0.Unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hNKqzGFeeXbj",
    "outputId": "88ec3494-f06a-42ae-a714-5e844e30c973"
   },
   "outputs": [],
   "source": [
    "#gs.model_analysis(df0,target='Unit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YBwAuPfEDbBo",
    "outputId": "dfc73823-5963-42fc-b599-031794039f36"
   },
   "outputs": [],
   "source": [
    "\t#definir target\n",
    "\n",
    "#df.target=df.Sinuosity_categories \n",
    "#df0.target=df0.Unit\n",
    "#print(df0.target.head())\n",
    "#print('Target',df0.Unit.unique()) #\n",
    "\n",
    "#df0.data=df0.drop(columns=['Unit', 'Group', 'sample']) #\n",
    "#print(df.data)\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "#print(df.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.Unit[df0['Unit']=='Cabecas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128    Cabecas\n",
      "129    Cabecas\n",
      "130    Cabecas\n",
      "131    Cabecas\n",
      "132    Cabecas\n",
      "Name: Unit, dtype: object\n",
      "16     Longa\n",
      "17     Longa\n",
      "18     Longa\n",
      "19     Longa\n",
      "120    Longa\n",
      "Name: Unit, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iande\\AppData\\Local\\Temp/ipykernel_8084/2568468313.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df1.target = df1.Unit\n",
      "C:\\Users\\iande\\AppData\\Local\\Temp/ipykernel_8084/2568468313.py:4: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df2.target = df2.Unit\n",
      "C:\\Users\\iande\\AppData\\Local\\Temp/ipykernel_8084/2568468313.py:6: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df3.target = df3.Unit\n",
      "C:\\Users\\iande\\AppData\\Local\\Temp/ipykernel_8084/2568468313.py:8: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df4.target = df4.Unit\n",
      "C:\\Users\\iande\\AppData\\Local\\Temp/ipykernel_8084/2568468313.py:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df5.target = df5.Unit\n",
      "C:\\Users\\iande\\AppData\\Local\\Temp/ipykernel_8084/2568468313.py:12: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df6.target = df6.Unit\n",
      "C:\\Users\\iande\\AppData\\Local\\Temp/ipykernel_8084/2568468313.py:14: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df7.target = df7.Unit\n",
      "C:\\Users\\iande\\AppData\\Local\\Temp/ipykernel_8084/2568468313.py:16: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df8.target = df8.Unit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60, 36)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df0.loc[df0['Unit']=='Cabecas']\n",
    "df1.target = df1.Unit\n",
    "df2 = df0.loc[df0['Unit']=='Longa']\n",
    "df2.target = df2.Unit\n",
    "df3 = df0.loc[df0['Unit']=='Motuca']\n",
    "df3.target = df3.Unit\n",
    "df4 = df0.loc[df0['Unit']=='Piaui']\n",
    "df4.target = df4.Unit\n",
    "df5 = df0.loc[df0['Unit']=='Pimenteiras']\n",
    "df5.target = df5.Unit\n",
    "df6 = df0.loc[df0['Unit']=='Poti']\n",
    "df6.target = df6.Unit\n",
    "df7 = df0.loc[df0['Unit']=='Sambaiba']\n",
    "df7.target = df7.Unit\n",
    "df8 = df0.loc[df0['Unit']=='Serra Grande']\n",
    "df8.target = df8.Unit\n",
    "print(df1.target.head())\n",
    "print(df2.target.head())\n",
    "len(df1.target),len(df2.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        BOSL1s      BOSLF      BOSLM      BOSLS  IRSL1.2s/BOSL1s    TL110oC  \\\n",
      "128  13.968898  35.085435  20.577181  44.337383         5.543432  61.978259   \n",
      "129  12.298183  35.170302  17.742161  47.087537         2.709581  65.869716   \n",
      "130  12.286076  33.647519  23.811382  42.541099         9.598168  68.804425   \n",
      "131  13.053657  42.947503  15.971914  41.080584         2.678601  64.414870   \n",
      "132  15.154258  43.654269  19.672789  36.672943         5.076820  23.752002   \n",
      "\n",
      "     TL110pos  TL325pos  \n",
      "128      94.4     329.4  \n",
      "129      94.4     333.0  \n",
      "130      96.2     327.6  \n",
      "131      94.4     329.4  \n",
      "132      89.0     327.6  \n",
      "       BOSL1s      BOSLF      BOSLM      BOSLS  IRSL1.2s/BOSL1s    TL110oC  \\\n",
      "16   6.384740  27.695152  12.471766  59.833082         9.496733  61.077474   \n",
      "17   6.743364  33.333000  33.333000  33.333000         7.270688  62.978625   \n",
      "18   6.479368  10.469115  25.200362  64.330523         6.177437  65.152833   \n",
      "19   5.951874  34.322368  37.710671  27.966960        23.253302  57.969076   \n",
      "120  3.469397   7.399375  21.453429  71.147196        92.475212  30.066513   \n",
      "\n",
      "     TL110pos  TL325pos  \n",
      "16       98.0     338.4  \n",
      "17       96.2     331.2  \n",
      "18       98.0     338.4  \n",
      "19       96.2     331.2  \n",
      "120      99.8     331.2  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iande\\AppData\\Local\\Temp/ipykernel_8084/640057547.py:1: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df1.data = df0.loc[df0['Unit']=='Cabecas'].drop(columns=['Unit', 'Group', 'sample'])\n",
      "C:\\Users\\iande\\AppData\\Local\\Temp/ipykernel_8084/640057547.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df2.data = df0.loc[df0['Unit']=='Longa'].drop(columns=['Unit', 'Group', 'sample'])\n",
      "C:\\Users\\iande\\AppData\\Local\\Temp/ipykernel_8084/640057547.py:3: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df3.data = df0.loc[df0['Unit']=='Motuca'].drop(columns=['Unit', 'Group', 'sample'])\n",
      "C:\\Users\\iande\\AppData\\Local\\Temp/ipykernel_8084/640057547.py:4: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df4.data = df0.loc[df0['Unit']=='Piaui'].drop(columns=['Unit', 'Group', 'sample'])\n",
      "C:\\Users\\iande\\AppData\\Local\\Temp/ipykernel_8084/640057547.py:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df5.data = df0.loc[df0['Unit']=='Pimenteiras'].drop(columns=['Unit', 'Group', 'sample'])\n",
      "C:\\Users\\iande\\AppData\\Local\\Temp/ipykernel_8084/640057547.py:6: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df6.data = df0.loc[df0['Unit']=='Poti'].drop(columns=['Unit', 'Group', 'sample'])\n",
      "C:\\Users\\iande\\AppData\\Local\\Temp/ipykernel_8084/640057547.py:7: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df7.data = df0.loc[df0['Unit']=='Sambaiba'].drop(columns=['Unit', 'Group', 'sample'])\n",
      "C:\\Users\\iande\\AppData\\Local\\Temp/ipykernel_8084/640057547.py:8: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df8.data = df0.loc[df0['Unit']=='Serra Grande'].drop(columns=['Unit', 'Group', 'sample'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.data = df0.loc[df0['Unit']=='Cabecas'].drop(columns=['Unit', 'Group', 'sample'])\n",
    "df2.data = df0.loc[df0['Unit']=='Longa'].drop(columns=['Unit', 'Group', 'sample'])\n",
    "df3.data = df0.loc[df0['Unit']=='Motuca'].drop(columns=['Unit', 'Group', 'sample'])\n",
    "df4.data = df0.loc[df0['Unit']=='Piaui'].drop(columns=['Unit', 'Group', 'sample'])\n",
    "df5.data = df0.loc[df0['Unit']=='Pimenteiras'].drop(columns=['Unit', 'Group', 'sample'])\n",
    "df6.data = df0.loc[df0['Unit']=='Poti'].drop(columns=['Unit', 'Group', 'sample'])\n",
    "df7.data = df0.loc[df0['Unit']=='Sambaiba'].drop(columns=['Unit', 'Group', 'sample'])\n",
    "df8.data = df0.loc[df0['Unit']=='Serra Grande'].drop(columns=['Unit', 'Group', 'sample'])\n",
    "\n",
    "print(df1.data.head())\n",
    "len(df1.data)\n",
    "\n",
    "print(df2.data.head())\n",
    "len(df2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zGQGZOHsEEPv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmin_max_scaler = sklearn.preprocessing.MinMaxScaler()\\n\\ndef scaleColumns(dfDat, cols_to_scale):\\n\\n\\n\\tn_test = dfDat[cols_to_scale]\\n#\\tprint('Cols',n_test)\\n\\tcols_to_norm = cols_to_scale\\n\\tx = n_test.values\\n\\tmin_max_scaler = sklearn.preprocessing.MinMaxScaler()\\n\\tx_scaled = min_max_scaler.fit_transform(x)\\n\\tn_test = pd.DataFrame(x_scaled, columns=cols_to_norm)\\n#\\tl_test = dfDat.drop(cols_to_norm, axis=1)\\n#\\tdf_out = pd.concat([n_test, l_test], axis=1)\\n\\tdf_out=n_test\\n\\treturn(df_out)\\n\\n\\n#df0.data=scaleColumns(df0.data,df0.data.columns)\\ndf1.data=scaleColumns(df1.data,df1.data.columns)#['Serra Grande' 'Longa' 'Sambaiba' 'Poti' 'Motuca' 'Piaui' 'Pimenteiras' 'Cabecas'])\\ndf2.data=scaleColumns(df2.data,df2.data.columns)\\ndf3.data=scaleColumns(df3.data,df3.data.columns)\\ndf4.data=scaleColumns(df4.data,df4.data.columns)\\ndf5.data=scaleColumns(df5.data,df5.data.columns)\\ndf6.data=scaleColumns(df6.data,df6.data.columns)\\ndf7.data=scaleColumns(df7.data,df7.data.columns)\\ndf8.data=scaleColumns(df8.data,df8.data.columns)\\n\\n#print(df.data)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\t\t# Normalizar\n",
    "\t\t# para escolher qual método https://stackoverflow.com/questions/30918781/right-function-for-normalizing-input-of-sklearn-svm\n",
    "\n",
    "#sklearn.preprocessing.scale(X) # standard scaler - assume distribuições normais e normaliza com média 0 e std 1\n",
    "\n",
    "#sklearn.preprocessing.normalize(X, axis=0) # normalizer - mantém os ângulos no espaço multidimensional mas não as magnitudes dentro de cada variável\n",
    "\n",
    "#sklearn.preprocessing.MinMaxScaler().fit_transform(X) - transforma cada variável em valores entre 0 e 1, sensível a outliers.\n",
    "\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "def scaleColumns(dfDat, cols_to_scale):\n",
    "\n",
    "\n",
    "\tn_test = dfDat[cols_to_scale]\n",
    "#\tprint('Cols',n_test)\n",
    "\tcols_to_norm = cols_to_scale\n",
    "\tx = n_test.values\n",
    "\tmin_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "\tx_scaled = min_max_scaler.fit_transform(x)\n",
    "\tn_test = pd.DataFrame(x_scaled, columns=cols_to_norm)\n",
    "#\tl_test = dfDat.drop(cols_to_norm, axis=1)\n",
    "#\tdf_out = pd.concat([n_test, l_test], axis=1)\n",
    "\tdf_out=n_test\n",
    "\treturn(df_out)\n",
    "\n",
    "\n",
    "#df0.data=scaleColumns(df0.data,df0.data.columns)\n",
    "df1.data=scaleColumns(df1.data,df1.data.columns)#['Serra Grande' 'Longa' 'Sambaiba' 'Poti' 'Motuca' 'Piaui' 'Pimenteiras' 'Cabecas'])\n",
    "df2.data=scaleColumns(df2.data,df2.data.columns)\n",
    "df3.data=scaleColumns(df3.data,df3.data.columns)\n",
    "df4.data=scaleColumns(df4.data,df4.data.columns)\n",
    "df5.data=scaleColumns(df5.data,df5.data.columns)\n",
    "df6.data=scaleColumns(df6.data,df6.data.columns)\n",
    "df7.data=scaleColumns(df7.data,df7.data.columns)\n",
    "df8.data=scaleColumns(df8.data,df8.data.columns)\n",
    "\n",
    "#print(df.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfhYblcsEy9r"
   },
   "source": [
    "Se o número de dados que caracteriza cada classe da variável alvo é muito diferente, a classificação fica enviesada.\n",
    "\n",
    "Em um procedimento semelhante ao boostrapping, podemos adicionar dados que ocupam valores à metade das distâncias dos dados reais no espaço multi-dimensoinal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgGYTgtqEbwh"
   },
   "source": [
    "Criando os datasets de treino e de teste "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eHcTeLouEgwj"
   },
   "outputs": [],
   "source": [
    "\t\t#criar dataset train e target\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df0.data, df0.target, test_size=0.44, random_state=50)\n",
    "\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(df1.data, df1.target, test_size=0.33, random_state=50) # 70% training and 30% test\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(df2.data, df2.target, test_size=0.33, random_state=50)\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(df3.data, df3.target, test_size=0.33, random_state=50)\n",
    "X_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(df4.data, df4.target, test_size=0.33, random_state=50)\n",
    "X_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(df5.data, df5.target, test_size=0.33, random_state=50)\n",
    "X_train_6, X_test_6, y_train_6, y_test_6 = train_test_split(df6.data, df6.target, test_size=0.33, random_state=50)\n",
    "X_train_7, X_test_7, y_train_7, y_test_7 = train_test_split(df7.data, df7.target, test_size=0.33, random_state=50)\n",
    "X_train_8, X_test_8, y_train_8, y_test_8 = train_test_split(df8.data, df8.target, test_size=0.33, random_state=50)\n",
    "\n",
    "#print(X_train_1.head())\n",
    "#print(y_train_1.head())\n",
    "\n",
    "X_train = np.concatenate((X_train_1, X_train_2, X_train_3, X_train_4, X_train_5, X_train_6, X_train_7, X_train_8))\n",
    "y_train = np.concatenate((y_train_1, y_train_2, y_train_3, y_train_4, y_train_5, y_train_6, y_train_7, y_train_8))\n",
    "X_test = np.concatenate((X_test_1, X_test_2, X_test_3, X_test_4, X_test_5, X_test_6, X_test_7, X_test_8))\n",
    "y_test = np.concatenate((y_test_1, y_test_2, y_test_3, y_test_4, y_test_5, y_test_6, y_test_7, y_test_8))\n",
    "\n",
    "#print(df1.target,df2.target)\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKqzGGzZdD3x",
    "tags": []
   },
   "source": [
    "# Algoritmos de classificação\n",
    "\n",
    "Vamos inicialmente tentar classificar nosso dataset de treino com um algoritmo que vimos anteriormente, o Modelo Gaussiano de Mistura, com 4 compoenntes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "id": "Zqz1Bg0eIT-a",
    "outputId": "cea5d5dc-d913-407d-d2f8-4ca38a40db1d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Cabecas</th>\n",
       "      <th>Longa</th>\n",
       "      <th>Motuca</th>\n",
       "      <th>Piaui</th>\n",
       "      <th>Pimenteiras</th>\n",
       "      <th>Poti</th>\n",
       "      <th>Sambaiba</th>\n",
       "      <th>Serra Grande</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cabecas</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longa</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Motuca</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Piaui</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pimenteiras</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poti</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sambaiba</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serra Grande</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0         Cabecas  Longa  Motuca  Piaui  Pimenteiras  Poti  Sambaiba  \\\n",
       "row_0                                                                      \n",
       "Cabecas            13      0       0      3            0     2         2   \n",
       "Longa               3      7       0      0            0     2         0   \n",
       "Motuca              1      1       3      1            0     1         0   \n",
       "Piaui               2      0       0      4            1     3         0   \n",
       "Pimenteiras         1      1       0      3            5     2         0   \n",
       "Poti                3      2       0      1            1    11         0   \n",
       "Sambaiba            1      0       0      0            0     3         7   \n",
       "Serra Grande        1      0       0      1            0     3         2   \n",
       "\n",
       "col_0         Serra Grande  \n",
       "row_0                       \n",
       "Cabecas                  0  \n",
       "Longa                    0  \n",
       "Motuca                   0  \n",
       "Piaui                    2  \n",
       "Pimenteiras              0  \n",
       "Poti                     1  \n",
       "Sambaiba                 0  \n",
       "Serra Grande            11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Accuracy: 0.5495495495495496\n"
     ]
    }
   ],
   "source": [
    "#SVM Create a svm Classifier\n",
    "#clf = svm.SVC(kernel='poly') # linear poly ou deffault Kernel kernel='poly'\n",
    "\n",
    "#RANDOM FOREST\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#KNN\n",
    "#\n",
    "#clf=KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "#Neural networks\n",
    "#clf=MLPClassifier(solver='lbfgs',max_iter=300)\n",
    "\n",
    "#Naive Bayes; can be MultinomialNB CategoricalNB BernoulliNB ComplementNB GaussianNB\n",
    "#clf=MultinomialNB()\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "#print(\"\\nRandom Forest\")\n",
    "\n",
    "df_confusion = pd.crosstab(y_test, y_pred)\n",
    "display(df_confusion)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "#df_metrics = pd.DataFrame({'Unit':np.unique(y_pred),\"Recall\":metrics.recall_score(y_test, y_pred,average=None),\"Precision\":metrics.precision_score(y_test, y_pred,average=None),\"F1\":metrics.f1_score(y_test, y_pred,average=None)})\n",
    "#display(df_metrics)\n",
    "\n",
    "#print('\\nFeature importance')\n",
    "\n",
    "\n",
    "#feature_imp = pd.Series(clf.feature_importances_,index=df.data.columns).sort_values(ascending=False)\n",
    "#print('\\n',feature_imp)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Aula 13 - Introdução ao Machine Learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
